{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MeghanaR123/Video_dehazing_project/blob/main/image_dehazing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ojbq5bY9gsMQ",
        "outputId": "8639fa03-0666-43fb-c67e-1891df0aaeb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.backends import cudnn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as tfs\n",
        "from torchvision.transforms import ToPILImage\n",
        "from torchvision.transforms import functional as FF\n",
        "import torchvision.utils as vutils\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.models import vgg16\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "SZxbrG5lqbQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def default_conv(in_channels, out_channels, kernel_size, bias=True):\n",
        "    return nn.Conv2d(in_channels, out_channels, kernel_size, padding=(kernel_size//2), bias=bias)\n",
        "\n",
        "\n",
        "class PALayer(nn.Module):\n",
        "    def __init__(self, channel):\n",
        "        super(PALayer, self).__init__()\n",
        "        self.pa = nn.Sequential(\n",
        "                nn.Conv2d(channel, channel // 8, 1, padding=0, bias=True),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(channel // 8, 1, 1, padding=0, bias=True),\n",
        "                nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        y = self.pa(x)\n",
        "        return x * y\n",
        "\n",
        "\n",
        "class CALayer(nn.Module):\n",
        "    def __init__(self, channel):\n",
        "        super(CALayer, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.ca = nn.Sequential(\n",
        "                nn.Conv2d(channel, channel // 8, 1, padding=0, bias=True),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(channel // 8, channel, 1, padding=0, bias=True),\n",
        "                nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.avg_pool(x)\n",
        "        y = self.ca(y)\n",
        "        return x * y\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, conv, dim, kernel_size,):\n",
        "        super(Block, self).__init__()\n",
        "        self.conv1 = conv(dim, dim, kernel_size, bias=True)\n",
        "        self.act1 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv(dim, dim, kernel_size, bias=True)\n",
        "        self.calayer = CALayer(dim)\n",
        "        self.palayer = PALayer(dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = self.act1(self.conv1(x))\n",
        "        res = res+x\n",
        "        res = self.conv2(res)\n",
        "        res = self.calayer(res)\n",
        "        res = self.palayer(res)\n",
        "        res += x\n",
        "        return res\n",
        "\n",
        "\n",
        "class Group(nn.Module):\n",
        "    def __init__(self, conv, dim, kernel_size, blocks):\n",
        "        super(Group, self).__init__()\n",
        "        modules = [Block(conv, dim, kernel_size)  for _ in range(blocks)]\n",
        "        modules.append(conv(dim, dim, kernel_size))\n",
        "        self.gp = nn.Sequential(*modules)\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = self.gp(x)\n",
        "        res += x\n",
        "        return res\n",
        "\n",
        "\n",
        "class FFA(nn.Module):\n",
        "    def __init__(self,gps,blocks,conv=default_conv):\n",
        "        super(FFA, self).__init__()\n",
        "        self.gps = gps\n",
        "        self.dim = 64\n",
        "        kernel_size = 3\n",
        "        pre_process = [conv(3, self.dim, kernel_size)]\n",
        "        assert self.gps==3\n",
        "        self.g1 = Group(conv, self.dim, kernel_size,blocks=blocks)\n",
        "        self.g2 = Group(conv, self.dim, kernel_size,blocks=blocks)\n",
        "        self.g3 = Group(conv, self.dim, kernel_size,blocks=blocks)\n",
        "        self.ca = nn.Sequential(*[\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(self.dim*self.gps,self.dim//16,1,padding=0),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.dim//16, self.dim*self.gps, 1, padding=0, bias=True),\n",
        "            nn.Sigmoid()\n",
        "            ])\n",
        "        self.palayer = PALayer(self.dim)\n",
        "\n",
        "        post_process = [\n",
        "            conv(self.dim, self.dim, kernel_size),\n",
        "            conv(self.dim, 3, kernel_size)]\n",
        "\n",
        "        self.pre = nn.Sequential(*pre_process)\n",
        "        self.post = nn.Sequential(*post_process)\n",
        "\n",
        "    def forward(self, x1):\n",
        "        x = self.pre(x1)\n",
        "        res1 = self.g1(x)\n",
        "        res2 = self.g2(res1)\n",
        "        res3 = self.g3(res2)\n",
        "        w = self.ca(torch.cat([res1,res2,res3],dim=1))\n",
        "        w = w.view(-1,self.gps, self.dim)[:,:,:,None,None]\n",
        "        out = w[:,0,::] * res1 + w[:,1,::] * res2+w[:,2,::] * res3\n",
        "        out = self.palayer(out)\n",
        "        x = self.post(out)\n",
        "        return x + x1"
      ],
      "metadata": {
        "id": "HLCAIuZCqeBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Default title text\n",
        "# Device name\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# Num residual_groups\n",
        "gps = 3\n",
        "# Num residual_blocks\n",
        "blocks = 19\n",
        "# Directory of test imgs\n",
        "img_dir = '/content/drive/MyDrive/synthetic-objective-testing-set-sots-reside/outdoor/hazy/'\n",
        "# Pre-trained checkpoint dir\n",
        "pretrained_model_dir = '/content/drive/MyDrive/synthetic-objective-testing-set-sots-reside/ffanet-pretrained-weights/' + f'ots_train_ffa_{gps}_{blocks}.pk'\n",
        "\n",
        "ckp = torch.load(pretrained_model_dir, map_location=device)\n",
        "net = FFA(gps=gps, blocks=blocks)\n",
        "net = nn.DataParallel(net)\n",
        "net.load_state_dict(ckp['model'])\n",
        "net.eval()\n",
        "ckp = torch.load(pretrained_model_dir, map_location=device)\n",
        "net = FFA(gps=gps, blocks=blocks)\n",
        "net = nn.DataParallel(net)\n",
        "net.load_state_dict(ckp['model'])\n",
        "net.eval()\n",
        "fname = '/content/drive/MyDrive/synthetic-objective-testing-set-sots-reside/outdoor/hazy/0001_0.8_0.2.jpg'\n",
        "haze = Image.open(fname)\n",
        "haze1 = tfs.Compose([\n",
        "    tfs.ToTensor(),\n",
        "    tfs.Normalize(mean=[0.64, 0.6, 0.58],std=[0.14,0.15, 0.152])\n",
        "])(haze)[None,::]\n",
        "haze_no = tfs.ToTensor()(haze)[None,::]\n",
        "with torch.no_grad():\n",
        "    pred = net(haze1)\n",
        "ts = torch.squeeze(pred.clamp(0,1).cpu())\n",
        "# tensorShow([haze_no, pred.clamp(0,1).cpu()],['haze', 'pred'])\n",
        "\n",
        "haze_no = make_grid(haze_no, nrow=1, normalize=True)\n",
        "ts = make_grid(ts, nrow=1, normalize=True)\n",
        "image_grid = torch.cat((haze_no, ts), -1)\n",
        "vutils.save_image(image_grid, '/content/drive/MyDrive/code/static/output.png')"
      ],
      "metadata": {
        "id": "hk5T-cNhqpb-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOorReHiN1ixo3EMFVphZuf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}