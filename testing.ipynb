{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyZZlCtrXCfGKmjVqkQpVC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MeghanaR123/Video_dehazing_project/blob/main/testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm8sJDQuiWCq",
        "outputId": "5e0c0cd3-6a4c-4c0a-b19b-f30b3d21743c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !kaggle datasets download -d balraj98/synthetic-objective-testing-set-sots-reside"
      ],
      "metadata": {
        "id": "1A6ruJTTlSDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !kaggle datasets download -d balraj98/ffanet-pretrained-weights"
      ],
      "metadata": {
        "id": "gUBP-J7Wo3MR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir /content/drive/MyDrive/synthetic-objective-testing-set-sots-reside\n",
        "# !unzip -q /content/synthetic-objective-testing-set-sots-reside.zip -d /content/drive/MyDrive/synthetic-objective-testing-set-sots-reside"
      ],
      "metadata": {
        "id": "vNt85zC-mJO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir /content/drive/MyDrive/synthetic-objective-testing-set-sots-reside/ffanet-pretrained-weights/\n",
        "# !unzip -q /content/ffanet-pretrained-weights.zip -d /content/drive/MyDrive/synthetic-objective-testing-set-sots-reside/ffanet-pretrained-weights/"
      ],
      "metadata": {
        "id": "8VgAjXBPpHcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import os"
      ],
      "metadata": {
        "id": "tUnUwv44nZ8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = glob.glob('/content/drive/MyDrive/synthetic-objective-testing-set-sots-reside/*')\n",
        "print(len(files))\n",
        "files_clear = glob.glob('/content/drive/MyDrive/synthetic-objective-testing-set-sots-reside/outdoor/clear/*')\n",
        "print(len(files_clear))\n",
        "files_hazy = glob.glob('/content/drive/MyDrive/synthetic-objective-testing-set-sots-reside/outdoor/hazy/*')\n",
        "print(len(files_hazy))\n",
        "weight = glob.glob('/content/drive/MyDrive/synthetic-objective-testing-set-sots-reside/ffanet-pretrained-weights/*')\n",
        "print(len(weight))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9ddZks6nbHC",
        "outputId": "39d59044-35ac-48f8-d351-6b802cc75b26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "492\n",
            "500\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "import time, math\n",
        "import argparse, random\n",
        "from math import exp\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.backends import cudnn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as tfs\n",
        "from torchvision.transforms import ToPILImage\n",
        "from torchvision.transforms import functional as FF\n",
        "import torchvision.utils as vutils\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.models import vgg16\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "wnZa011tio8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device name\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# Num residual_groups\n",
        "gps = 3\n",
        "# Num residual_blocks\n",
        "blocks = 19\n",
        "# Directory of test imgs\n",
        "img_dir = '/content/drive/MyDrive/synthetic-objective-testing-set-sots-reside/outdoor/hazy/'\n",
        "# Pre-trained checkpoint dir\n",
        "pretrained_model_dir = '/content/drive/MyDrive/synthetic-objective-testing-set-sots-reside/ffanet-pretrained-weights/' + f'ots_train_ffa_{gps}_{blocks}.pk'\n",
        "# Output dir to save predicted de-hazed images\n",
        "output_dir = f'/content/pred_FFA_ots/'\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)"
      ],
      "metadata": {
        "id": "KSUcZkCNi2PJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tensorShow(tensors,titles=None):\n",
        "    '''t:BCWH'''\n",
        "    fig=plt.figure()\n",
        "    for tensor, title, i in zip(tensors, titles, range(len(tensors))):\n",
        "        img = make_grid(tensor)\n",
        "        npimg = img.numpy()\n",
        "        ax = fig.add_subplot(211+i)\n",
        "        ax.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "        ax.set_title(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "hPErSN5Wi5vB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def default_conv(in_channels, out_channels, kernel_size, bias=True):\n",
        "    return nn.Conv2d(in_channels, out_channels, kernel_size, padding=(kernel_size//2), bias=bias)\n",
        "\n",
        "\n",
        "class PALayer(nn.Module):\n",
        "    def __init__(self, channel):\n",
        "        super(PALayer, self).__init__()\n",
        "        self.pa = nn.Sequential(\n",
        "                nn.Conv2d(channel, channel // 8, 1, padding=0, bias=True),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(channel // 8, 1, 1, padding=0, bias=True),\n",
        "                nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        y = self.pa(x)\n",
        "        return x * y\n",
        "\n",
        "\n",
        "class CALayer(nn.Module):\n",
        "    def __init__(self, channel):\n",
        "        super(CALayer, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.ca = nn.Sequential(\n",
        "                nn.Conv2d(channel, channel // 8, 1, padding=0, bias=True),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(channel // 8, channel, 1, padding=0, bias=True),\n",
        "                nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.avg_pool(x)\n",
        "        y = self.ca(y)\n",
        "        return x * y\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, conv, dim, kernel_size,):\n",
        "        super(Block, self).__init__()\n",
        "        self.conv1 = conv(dim, dim, kernel_size, bias=True)\n",
        "        self.act1 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv(dim, dim, kernel_size, bias=True)\n",
        "        self.calayer = CALayer(dim)\n",
        "        self.palayer = PALayer(dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = self.act1(self.conv1(x))\n",
        "        res = res+x\n",
        "        res = self.conv2(res)\n",
        "        res = self.calayer(res)\n",
        "        res = self.palayer(res)\n",
        "        res += x\n",
        "        return res\n",
        "\n",
        "\n",
        "class Group(nn.Module):\n",
        "    def __init__(self, conv, dim, kernel_size, blocks):\n",
        "        super(Group, self).__init__()\n",
        "        modules = [Block(conv, dim, kernel_size)  for _ in range(blocks)]\n",
        "        modules.append(conv(dim, dim, kernel_size))\n",
        "        self.gp = nn.Sequential(*modules)\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = self.gp(x)\n",
        "        res += x\n",
        "        return res\n",
        "\n",
        "\n",
        "class FFA(nn.Module):\n",
        "    def __init__(self,gps,blocks,conv=default_conv):\n",
        "        super(FFA, self).__init__()\n",
        "        self.gps = gps\n",
        "        self.dim = 64\n",
        "        kernel_size = 3\n",
        "        pre_process = [conv(3, self.dim, kernel_size)]\n",
        "        assert self.gps==3\n",
        "        self.g1 = Group(conv, self.dim, kernel_size,blocks=blocks)\n",
        "        self.g2 = Group(conv, self.dim, kernel_size,blocks=blocks)\n",
        "        self.g3 = Group(conv, self.dim, kernel_size,blocks=blocks)\n",
        "        self.ca = nn.Sequential(*[\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(self.dim*self.gps,self.dim//16,1,padding=0),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.dim//16, self.dim*self.gps, 1, padding=0, bias=True),\n",
        "            nn.Sigmoid()\n",
        "            ])\n",
        "        self.palayer = PALayer(self.dim)\n",
        "\n",
        "        post_process = [\n",
        "            conv(self.dim, self.dim, kernel_size),\n",
        "            conv(self.dim, 3, kernel_size)]\n",
        "\n",
        "        self.pre = nn.Sequential(*pre_process)\n",
        "        self.post = nn.Sequential(*post_process)\n",
        "\n",
        "    def forward(self, x1):\n",
        "        x = self.pre(x1)\n",
        "        res1 = self.g1(x)\n",
        "        res2 = self.g2(res1)\n",
        "        res3 = self.g3(res2)\n",
        "        w = self.ca(torch.cat([res1,res2,res3],dim=1))\n",
        "        w = w.view(-1,self.gps, self.dim)[:,:,:,None,None]\n",
        "        out = w[:,0,::] * res1 + w[:,1,::] * res2+w[:,2,::] * res3\n",
        "        out = self.palayer(out)\n",
        "        x = self.post(out)\n",
        "        return x + x1"
      ],
      "metadata": {
        "id": "4t4b_ScTi88Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ckp = torch.load(pretrained_model_dir, map_location=device)\n",
        "net = FFA(gps=gps, blocks=blocks)\n",
        "net = nn.DataParallel(net)\n",
        "net.load_state_dict(ckp['model'])\n",
        "net.eval()\n",
        "\n",
        "img_paths = sorted(os.listdir(img_dir))\n",
        "\n",
        "for im in img_paths:\n",
        "    haze = Image.open(img_dir+im)\n",
        "    haze1 = tfs.Compose([\n",
        "        tfs.ToTensor(),\n",
        "        tfs.Normalize(mean=[0.64, 0.6, 0.58],std=[0.14,0.15, 0.152])\n",
        "    ])(haze)[None,::]\n",
        "    haze_no = tfs.ToTensor()(haze)[None,::]\n",
        "    with torch.no_grad():\n",
        "        pred = net(haze1)\n",
        "    ts = torch.squeeze(pred.clamp(0,1).cpu())\n",
        "    # tensorShow([haze_no, pred.clamp(0,1).cpu()],['haze', 'pred'])\n",
        "\n",
        "    haze_no = make_grid(haze_no, nrow=1, normalize=True)\n",
        "    ts = make_grid(ts, nrow=1, normalize=True)\n",
        "    image_grid = torch.cat((haze_no, ts), -1)\n",
        "    vutils.save_image(image_grid, output_dir+im.split('.')[0]+'_FFA.png')"
      ],
      "metadata": {
        "id": "L5svAacRjIeh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}